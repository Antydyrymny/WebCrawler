<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!-- CSS -->
        <link rel="stylesheet" href="./css/style.css" />
        <link rel="stylesheet" href="./css/spinner.css" />
        <!-- Fonts -->
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=Montserrat&family=Roboto&display=swap"
            rel="stylesheet"
        />
        <!-- D3 CDN -->
        <script src="https://d3js.org/d3.v7.min.js"></script>
        <title>Web Graph</title>
    </head>
    <body>
        <div class="wrapper">
            <div class="content">
                <h1>Web crawler with graph visualization</h1>
                <p class="subheading">
                    Dynamically generating interactive website graphs using web crawling
                    and D3.js visualization
                </p>
                <br />
                <div class="graph">
                    <div class="svg-wrapper">
                        <div id="spinner">
                            <div></div>
                            <div></div>
                            <div></div>
                            <div></div>
                            <div></div>
                            <div></div>
                            <div></div>
                            <div></div>
                        </div>
                        <svg></svg>
                    </div>
                </div>
                <div class="description graphDescription">
                    *Click on a node to further map the graph <br />
                    **Arrows show the direction of connection, two-ways connections are
                    shown as blue lines
                </div>
                <div class="form-wrapper">
                    <div class="form-container">
                        <form id="webCrawlerQuerry">
                            <div>
                                <label for="query">Enter domain to build its graph</label
                                ><br />
                                <input
                                    type="text"
                                    id="query"
                                    name="query"
                                    placeholder="Like https://www.MDN.com or MDN.com"
                                    autocomplete="url"
                                />
                            </div>
                        </form>
                    </div>
                </div>
                <div class="examplesGallery">
                    <div class="galleryItem" id="galleryItem1">
                        <img src="./src/assets/images/github.jpg" alt="Github graph" />
                    </div>
                    <div class="galleryItem" id="galleryItem2">
                        <img src="./src/assets/images/mdn.jpg" alt="MDN graph" />
                    </div>
                    <div class="galleryItem" id="galleryItem3">
                        <img src="./src/assets/images/google.jpg" alt="Google graph" />
                    </div>
                </div>
                <div class="description exampleDescription">
                    *Some example graphs, click to load
                </div>
                <article>
                    <h2>About</h2>
                    <p>
                        This project is a web-based platform that allows users to explore
                        the structures of websites through an interactive graph generated
                        using D3.js. The platform utilizes a simple web crawler script,
                        employing the breadth-first search algorithm to traverse websites
                        by mapping link elements in their HTML to collect data about their
                        interconnections and visualize it.
                    </p>
                    <p>
                        By entering a domain in the input field, you will prompt the
                        crawler script to explore and map the respective website, building
                        its graph. In the resulting graph, nodes represent individual
                        pages, while links between nodes signify their associations.
                    </p>
                    <p>
                        Here I will discuss the design and implementation of the platform,
                        the challenges faced during its development, and limitations
                        related to certain web technologies.
                    </p>
                    <h2>Web Crawler Overview</h2>
                    <p>
                        Upon entering a domain, its URL is sent to the server to handle
                        cross-origin requests, where the web crawler runs starting with
                        the root page.
                    </p>
                    <p>The code looks something like this:</p>
                    <pre>
                        <code>
                            <span class="opeartor">async function</span> <span class="name">crawler</span>({ url, explored, maxNodeCount }) {
                                <span class="opeartor">if</span> (!<span class="name">validateURL</span>(url)) <span class="opeartor">throw</span> new Error('URL is invalid');

                                const treeRoot = new InnerNode(url);
                                const toVisit = [treeRoot];

                                <span class="comment">// Breadth-first search</span>
                                <span class="opeartor">while</span> (toVisit.length) {
                                    const currentlyVisiting = toVisit.shift();
                                    <span class="comment">// Stop condition: already explored or another domain</span>
                                    <span class="opeartor">if</span> (explored.has(currentlyVisiting.url.href) || !currentlyVisiting.inner) <span class="opeartor">continue</span>;

                                    <span class="comment">// Process each site for links by building it's DOM</span>
                                    const containedNodes = <span class="opeartor">await</span> <span class="name">processUrl</span>(currentlyVisiting.url);
                                    containedNodes.forEach((node) => {
                                        currentlyVisiting.connect(node);
                                    });
                                    toVisit.push(...containedNodes);

                                    <span class="comment">//Mark as processed</span>
                                    explored.add(currentlyVisiting.url.href);
                                    currentlyVisiting.explored = true;
                                }
                                <span class="opeartor">return</span> { treeRoot, explored };
                            }
                        </code>
                    </pre>
                    <p>
                        As each page is visited, relevant information, such as page URLs
                        and their associated links, is collected and stored in a data
                        structure suitable for the graph. This data is sent to the
                        front-end, processed, and visualized using D3.js to create the
                        interactive graph.
                    </p>
                    <h2>Graph Visualization with D3.js</h2>
                    <p>
                        D3.js provides a lot of useful tools for data visualization.
                        Specifically, for creating graphs, there is a force-simulation
                        API. Working with it involves the following steps:
                    </p>
                    <ol>
                        <li>
                            <b>Creating a simulation</b> from a collection of data with
                            respective arrays <code>nodes</code> and
                            <code>links</code> using D3.js methods
                            <code>d3.forceSimulation(data.nodes)</code>,
                        </li>
                        <li>
                            <b>Adding desired forces</b> to it (fine-tuning strength
                            coefficients of said forces to achieve the preferred look and
                            feel of the graph proved to be a challenging process). The
                            most notable forces used in this project are:
                            <code>'link'</code> - to connect the nodes,
                            <code>'charge'</code> - to make them repel from one another.
                            There are others to position the graph and make nodes of the
                            same domain stick closer to each other.
                        </li>
                        <li>
                            <b>Visualizing nodes and links</b> by creating the
                            <code>'line'</code> and <code>'circle'</code> selections,
                            associating them with respective data, and representing them
                            with SVG elements. For instance, code for creating a
                            <code>'line'</code> selection can look like this:
                            <pre>
                                <code>
                                    let linkGroup = svg.select('g.links');
                                    <span class="opeartor">if</span> (linkGroup.empty()) linkGroup = svg.append('g').attr('class', 'links');
                                    const links = linkGroup.selectAll('line')
                                        .data(data.links, (d) => `${d.source.id}-${d.target.id}`)
                                        .enter()
                                        .append('line')
                                        .attr('stroke', linkColor)
                                        .attr('stroke-width', (d) => d.strength)
                                        <span class="comment">//Style the end of the line with an arrowhead with respective direction
                                        //or color link separately if connection is in both directions</span>
                                        .each(function (d) {
                                            const link = d3.select(this);
                                            const reverseLink = data.links.find(
                                                (l) => l.source.id === d.target.id && l.target.id === d.source.id
                                            );
                                            <span class="opeartor">if</span> (reverseLink) {
                                                d.bidirectional = true;
                                                reverseLink.bidirectional = true;
                                                link.attr('stroke', bidirectionalLinkColor).attr('marker-end', '');
                                            } <span class="opeartor">else</span> {
                                                link.attr('marker-end', 'url(#arrowhead)');
                                            }
                                        });
                                </code>
                            </pre>
                            Selections can later be updated when new nodes and links are
                            added.
                        </li>
                    </ol>
                    <h2>Challenges and Limitations</h2>
                    <p>
                        It is important to note that in this project, site connections are
                        found by extracting links from their HTML. While this approach
                        works in many cases, it may not suffice for pages that load
                        content dynamically, especially those utilizing frameworks like
                        React or Angular. To properly crawl JavaScript-generated websites,
                        it would require executing all of the page's scripts and
                        generating its HTML. This can be achieved with a headless browser,
                        but such a process is more computationally intensive and may not
                        be suitable for rendering graphs dynamically. Therefore, crawling
                        such websites falls outside the scope of this project, which
                        focuses on exploring static HTML-based websites.
                    </p>
                    <p>
                        Even without scraping JavaScript-generated websites, and using a
                        rather straightforward algorithm, there are still some caveats
                        that mostly come down to dealing with URLs.
                    </p>
                    <p>
                        Firstly, URLs need to be validated to ensure that the crawler
                        identifies and collects only relevant links within websites.
                        Non-website elements, such as email addresses, telephone numbers,
                        script files, etc., need to be excluded. Additionally, resolving
                        links can be tricky due to various link types, including absolute,
                        relative, and those within the scope of the <code>base</code> tag,
                        which can contain relative links themselves. It is important to
                        also normalize URLs, as links on the pages can look different but
                        lead to the same resource. All of these scenarios need to be
                        accounted for.
                    </p>
                    <p>
                        In any case, it was an interesting side project to work on. If you
                        want to play with it, customize the look of the graph, or add some
                        functionality, you can find the project's source code on the
                        <a href="https://github.com/Antydyrymny/WebCrawler">GitHub page</a
                        >. Feel free to check it out and have some fun experimenting with
                        the web crawler and the graph!
                    </p>
                </article>
            </div>
        </div>
        <!-- Main script -->
        <script type="module" src="./src/js/main.js"></script>
    </body>
</html>
